apiVersion: v1
kind: Service
metadata:
  name: canoe
spec:
  clusterIP: None
  selector:
    app: canoe
  ports:
    - name: master
      port: 29500
      targetPort: 29500
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: canoe
spec:
  serviceName: canoe
  replicas: 3
  podManagementPolicy: Parallel

  selector:
    matchLabels:
      app: canoe

  template:
    metadata:
      labels:
        app: canoe
    spec:
      restartPolicy: Always
      terminationGracePeriodSeconds: 30

      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: kubernetes.io/hostname
                    operator: In
                    values:
                      - csrwks2024-0242.engin.umich.edu
                      - csrwks2024-0243.engin.umich.edu
                      - csrwks2024-0244.engin.umich.edu
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app: canoe
              topologyKey: kubernetes.io/hostname

      containers:
        - name: canoe
          image: luminoctum/ubuntu22.04-cuda12.9-py3.10-canoe:2026-01-31b
          imagePullPolicy: IfNotPresent

          ports:
            - name: master
              containerPort: 29500

          resources:
            limits:
              nvidia.com/gpu: 2
              cpu: "2"
              memory: "20Gi"
            requests:
              nvidia.com/gpu: 2
              cpu: "2"
              memory: "20Gi"

          env:
            - name: MASTER_ADDR
              value: canoe-0.canoe
            - name: MASTER_PORT
              value: "29500"
            - name: GPUS_PER_NODE
              value: "2"
            - name: WORLD_SIZE
              value: "6"
            - name: CUDA_VISIBLE_DEVICES
              value: "0,1"

          volumeMounts:
            - name: model-data
              mountPath: /data
            - name: dshm
              mountPath: /dev/shm

          command: ["/bin/bash", "-lc"]
          args:
            - |
              set -euo pipefail

              NODE_RANK="${HOSTNAME##*-}"

              echo "HOSTNAME=${HOSTNAME}"
              echo "NODE_RANK=${NODE_RANK}"
              echo "MASTER_ADDR=${MASTER_ADDR}"
              echo "MASTER_PORT=${MASTER_PORT}"
              echo "WORLD_SIZE=${WORLD_SIZE}"
              echo "GPUS_PER_NODE=${GPUS_PER_NODE}"
              echo "CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES}"

              for LOCAL_RANK in 0 1; do
                RANK=$(( NODE_RANK * GPUS_PER_NODE + LOCAL_RANK ))
                echo "Launching RANK=${RANK} LOCAL_RANK=${LOCAL_RANK}"

                RANK=${RANK} \
                WORLD_SIZE=${WORLD_SIZE} \
                LOCAL_RANK=${LOCAL_RANK} \
                MASTER_ADDR=${MASTER_ADDR} \
                MASTER_PORT=${MASTER_PORT} \
                CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES} \
                echo "AA" &   # <-- REPLACE with your real command
              done

              wait

      volumes:
        - name: model-data
          hostPath:
            path: /home/chengcli/data
            type: Directory
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: "8Gi"
